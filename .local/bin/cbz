#!/usr/bin/env -S uv run --script
# /// script
# requires-python = ">=3.10"
# dependencies = [
#     "lxml",
#     "pillow",
#     "pymupdf",
# ]
# ///
"""
CBZ utilities: convert EPUB/PDF to CBZ, rename images, extract pages, split spreads.

Usage:
    cbz -c [input.epub|pdf]   Convert EPUB/PDF to CBZ with original format (no arg = all .epub/.pdf)
    cbz -c [input] --webp     Convert to WebP (default quality 85)
    cbz -r [input.cbz]        Rename images to 001.ext, 002.ext, ... (no arg = all .cbz)
    cbz -e <N> [input.cbz]    Extract Nth page from end (no arg = all .cbz)
    cbz -s [input.cbz]        Split two-page spreads RTL (no arg = all .cbz)
    cbz -s [input.cbz] --ltr  Split two-page spreads LTR (no arg = all .cbz)
    cbz -a [input.cbz]        Add blank page after cover (no arg = all .cbz)
    cbz -w [input.cbz]        Convert images to WebP lossy q80 (no arg = all .cbz)
    cbz -w [input.cbz] -q 90  Convert to WebP with quality 90
    cbz -w [input.cbz] --lossless  Convert to lossless WebP
"""

import argparse
import io
import os
import re
import sys
import tempfile
import zipfile
from pathlib import Path
from urllib.parse import unquote, urljoin
import fitz
from lxml import etree
from PIL import Image

NAMESPACES = {
    "container": "urn:oasis:names:tc:opendocument:xmlns:container",
    "opf": "http://www.idpf.org/2007/opf",
    "xhtml": "http://www.w3.org/1999/xhtml",
}


def get_opf_path(epub: zipfile.ZipFile) -> str:
    """Get the path to the OPF file from container.xml."""
    container = etree.fromstring(epub.read("META-INF/container.xml"))
    rootfile = container.find(".//container:rootfile", NAMESPACES)
    if rootfile is None:
        raise ValueError("Could not find rootfile in container.xml")
    return rootfile.get("full-path")


def parse_opf(epub: zipfile.ZipFile, opf_path: str) -> tuple[list[tuple[str, str]], dict[str, str]]:
    """Parse OPF and return spine order (list of (href, properties)) and manifest (id -> href)."""
    opf_content = epub.read(opf_path)
    opf = etree.fromstring(opf_content)
    opf_dir = str(Path(opf_path).parent)

    # Build manifest: id -> href (resolved to full path in EPUB)
    manifest = {}
    for item in opf.findall(".//opf:manifest/opf:item", NAMESPACES):
        item_id = item.get("id")
        href = item.get("href")
        if item_id and href:
            # Resolve relative path
            full_path = urljoin(opf_dir + "/", unquote(href))
            manifest[item_id] = full_path.lstrip("/")

    # Get spine order with properties
    spine_items = []
    for itemref in opf.findall(".//opf:spine/opf:itemref", NAMESPACES):
        idref = itemref.get("idref")
        properties = itemref.get("properties", "")
        if idref and idref in manifest:
            spine_items.append((manifest[idref], properties))

    return spine_items, manifest


def extract_images_from_xhtml(
    epub: zipfile.ZipFile, xhtml_path: str, manifest_hrefs: set[str]
) -> list[str]:
    """Extract image paths from an XHTML document in spine order."""
    try:
        content = epub.read(xhtml_path)
    except KeyError:
        return []

    try:
        doc = etree.fromstring(content)
    except etree.XMLSyntaxError:
        # Try as HTML
        doc = etree.HTML(content)

    xhtml_dir = str(Path(xhtml_path).parent)
    images = []

    # Find all img tags and image elements (including SVG images)
    for img in doc.iter():
        src = None
        if img.tag in ("{http://www.w3.org/1999/xhtml}img", "img"):
            src = img.get("src")
        elif img.tag in ("{http://www.w3.org/1999/xhtml}image", "image", "{http://www.w3.org/2000/svg}image"):
            src = img.get("{http://www.w3.org/1999/xlink}href") or img.get("href")

        if src:
            # Resolve relative path
            full_path = urljoin(xhtml_dir + "/", unquote(src))
            full_path = full_path.lstrip("/")
            # Normalize path (handle ../)
            full_path = str(Path(full_path).as_posix())
            # Only include if it's in the manifest (i.e., it's a real image in the EPUB)
            if full_path in manifest_hrefs or any(
                h.endswith("/" + full_path.split("/")[-1]) for h in manifest_hrefs
            ):
                images.append(full_path)

    return images


def get_spine_images(epub: zipfile.ZipFile, opf_path: str) -> list[tuple[str | None, str]]:
    """Get all images referenced in the spine, in order.

    Returns list of (image_path or None for blank, properties).
    """
    spine_items, manifest = parse_opf(epub, opf_path)
    manifest_hrefs = set(manifest.values())

    # Check if this EPUB uses spread properties (indicates manga/comic with two-page layout)
    has_spread_properties = any("page-spread" in props for _, props in spine_items)

    # Also create a lookup for files that exist in the EPUB
    epub_files = set(epub.namelist())

    seen = set()
    ordered_images = []

    for xhtml_path, properties in spine_items:
        images = extract_images_from_xhtml(epub, xhtml_path, manifest_hrefs)

        if not images:
            # Only preserve blank slots if EPUB uses spread properties (for proper alignment)
            if has_spread_properties:
                ordered_images.append((None, properties))
            # Otherwise skip pages with no images (old behavior for non-spread EPUBs)
        else:
            for img in images:
                # Try to find the actual file path in the EPUB
                actual_path = None
                if img in epub_files:
                    actual_path = img
                else:
                    # Try without leading components or with different path
                    for f in epub_files:
                        if f.endswith(img.split("/")[-1]):
                            actual_path = f
                            break

                if actual_path and actual_path not in seen:
                    seen.add(actual_path)
                    ordered_images.append((actual_path, properties))

    return ordered_images


def create_cbz(output_path: Path, images: list[tuple[str, bytes]]) -> None:
    """Create a CBZ file from a list of images."""
    temp_fd, temp_path = tempfile.mkstemp(suffix=".cbz", dir=output_path.parent)
    try:
        with zipfile.ZipFile(temp_path, "w", zipfile.ZIP_DEFLATED) as cbz:
            for idx, (original_path, data) in enumerate(images, 1):
                ext = Path(original_path).suffix.lower()
                new_name = f"{idx:03d}{ext}"
                cbz.writestr(new_name, data)
        Path(temp_path).replace(output_path)
    finally:
        try:
            os.close(temp_fd)
        except OSError:
            pass
        try:
            Path(temp_path).unlink(missing_ok=True)
        except OSError:
            pass


def convert_epub_to_cbz(epub_path: Path, use_webp: bool = False, quality: int = 85) -> None:
    """Convert EPUB to CBZ, preserving blank pages for proper spread alignment."""
    if not epub_path.exists():
        print(f"Error: File not found: {epub_path}", file=sys.stderr)
        sys.exit(1)

    output_path = epub_path.with_suffix(".cbz")

    with zipfile.ZipFile(epub_path, "r") as epub:
        opf_path = get_opf_path(epub)
        spine_images = get_spine_images(epub, opf_path)

        if not spine_images:
            print("No pages found in spine.", file=sys.stderr)
            sys.exit(1)

        # Count actual images vs blank pages
        image_count = sum(1 for img, _ in spine_images if img is not None)
        blank_count = sum(1 for img, _ in spine_images if img is None)

        fmt_info = f"WebP q{quality}" if use_webp else "original format"
        print(f"Found {len(spine_images)} pages in spine ({image_count} images, {blank_count} blank) -> {fmt_info}")

        # Find reference dimensions from first actual image
        ref_width, ref_height = 900, 1350  # Default fallback
        ref_ext = ".webp" if use_webp else ".jpg"
        for img_path, _ in spine_images:
            if img_path is not None:
                try:
                    data = epub.read(img_path)
                    img = Image.open(io.BytesIO(data))
                    ref_width, ref_height = img.width, img.height
                    if not use_webp:
                        ref_ext = Path(img_path).suffix.lower()
                    break
                except Exception:
                    pass

        # Read all image data, generating blank pages as needed
        images = []
        spread_info = []
        for img_path, properties in spine_images:
            if img_path is None:
                # Generate blank page with reference dimensions
                blank_img = Image.new("RGB", (ref_width, ref_height), (255, 255, 255))
                if use_webp:
                    buf = io.BytesIO()
                    blank_img.save(buf, format="WEBP", quality=quality)
                    data = buf.getvalue()
                    images.append(("blank.webp", data))
                else:
                    data = image_to_bytes(blank_img, ref_ext.lstrip("."))
                    images.append((f"blank{ref_ext}", data))
                spread_info.append(("blank", properties))
            else:
                try:
                    data = epub.read(img_path)
                    img = Image.open(io.BytesIO(data))

                    # Check for transparent images and skip them
                    is_transparent = False
                    if img.mode == 'RGBA':
                        extrema = img.getchannel('A').getextrema()
                        # If max alpha is very low, it's basically transparent
                        if extrema[1] < 10:
                            is_transparent = True

                    if is_transparent:
                        # Skip adding the transparent image to the list
                        print(f"  Info: Skipped transparent image {img_path}.")
                    else:
                        if use_webp:
                            # Convert to WebP
                            if img.mode in ("RGBA", "LA", "PA"):
                                pass  # Keep alpha
                            elif img.mode != "RGB":
                                img = img.convert("RGB")
                            buf = io.BytesIO()
                            img.save(buf, format="WEBP", quality=quality)
                            images.append(("converted.webp", buf.getvalue()))
                        else:
                            images.append((img_path, data))
                        spread_info.append((img_path, properties))

                except KeyError:
                    print(f"Warning: Could not read {img_path}", file=sys.stderr)

        # Report spread alignment
        spread_left = sum(1 for _, p in spread_info if "page-spread-left" in p)
        spread_right = sum(1 for _, p in spread_info if "page-spread-right" in p)
        if spread_left or spread_right:
            print(f"  Spread layout: {spread_left} left, {spread_right} right")

    create_cbz(output_path, images)
    print(f"Created: {output_path}")


def convert_pdf_to_cbz(pdf_path: Path, use_webp: bool = False, quality: int = 85) -> None:
    """Convert PDF to CBZ, rendering each page as an image."""
    if not pdf_path.exists():
        print(f"Error: File not found: {pdf_path}", file=sys.stderr)
        sys.exit(1)

    output_path = pdf_path.with_suffix(".cbz")

    doc = fitz.open(pdf_path)
    total_pages = len(doc)

    fmt_info = f"WebP q{quality}" if use_webp else "PNG"
    print(f"Converting {total_pages} pages -> {fmt_info}")

    images = []
    for page_num in range(total_pages):
        print(f"\r  Processing page {page_num + 1}/{total_pages}...", end="", flush=True)
        page = doc[page_num]
        # Render at 2x for good quality (default is 72 DPI, this gives 144 DPI)
        mat = fitz.Matrix(2, 2)
        pix = page.get_pixmap(matrix=mat)

        if use_webp:
            # Convert to PIL Image then to WebP
            img = Image.frombytes("RGB", (pix.width, pix.height), pix.samples)
            buf = io.BytesIO()
            img.save(buf, format="WEBP", quality=quality)
            images.append(("page.webp", buf.getvalue()))
        else:
            # Use PNG
            images.append(("page.png", pix.tobytes("png")))

    doc.close()
    print()  # Clear progress line

    create_cbz(output_path, images)
    print(f"Created: {output_path}")


def natural_sort_key(s: str) -> list:
    """Generate a key for natural sorting (handles numeric parts correctly).

    '2.jpg' comes before '10.jpg', 'page1' before 'page10', etc.
    Sorts by basename only (ignores directory path).
    """
    # Use only the filename for sorting, not the full path
    basename = Path(s).name
    return [
        int(part) if part.isdigit() else part.lower()
        for part in re.split(r'(\d+)', basename)
    ]


def get_image_files(cbz: zipfile.ZipFile) -> list[str]:
    """Get naturally sorted list of image files from CBZ."""
    image_extensions = {".jpg", ".jpeg", ".png", ".gif", ".webp", ".bmp", ".tiff", ".tif"}
    images = []
    for name in cbz.namelist():
        # Skip macOS resource forks and metadata
        if name.startswith("__MACOSX/") or Path(name).name.startswith("._"):
            continue
        if Path(name).suffix.lower() in image_extensions:
            images.append(name)
    return sorted(images, key=natural_sort_key)


def rename_images_in_cbz(cbz_path: Path) -> None:
    """Rename all images in CBZ to 001.ext, 002.ext, etc."""
    if not cbz_path.exists():
        print(f"Error: File not found: {cbz_path}", file=sys.stderr)
        sys.exit(1)

    temp_fd, temp_path = tempfile.mkstemp(suffix=".cbz", dir=cbz_path.parent)
    try:
        with zipfile.ZipFile(cbz_path, "r") as cbz_in:
            images = get_image_files(cbz_in)
            if not images:
                print("No images found in CBZ.", file=sys.stderr)
                sys.exit(1)

            print(f"Renaming {len(images)} images...")
            for i, img in enumerate(images[:5], 1):
                print(f"  {i}: {img}")
            if len(images) > 5:
                print(f"  ... ({len(images) - 5} more)")

            with zipfile.ZipFile(temp_path, "w", zipfile.ZIP_DEFLATED) as cbz_out:
                for idx, img_path in enumerate(images, 1):
                    ext = Path(img_path).suffix.lower()
                    new_name = f"{idx:03d}{ext}"
                    data = cbz_in.read(img_path)
                    cbz_out.writestr(new_name, data)

        Path(temp_path).replace(cbz_path)
        print(f"Renamed images in: {cbz_path}")
    finally:
        try:
            os.close(temp_fd)
        except OSError:
            pass
        try:
            Path(temp_path).unlink(missing_ok=True)
        except OSError:
            pass


def extract_page_from_end(cbz_path: Path, n: int) -> None:
    """Extract the Nth page from the end (1=last, 2=second-to-last, etc.)."""
    if not cbz_path.exists():
        print(f"Error: File not found: {cbz_path}", file=sys.stderr)
        sys.exit(1)

    if n < 1:
        print("Error: Page number must be >= 1", file=sys.stderr)
        sys.exit(1)

    with zipfile.ZipFile(cbz_path, "r") as cbz:
        images = get_image_files(cbz)
        if not images:
            print("No images found in CBZ.", file=sys.stderr)
            sys.exit(1)

        if n > len(images):
            print(f"Error: Only {len(images)} images in CBZ, cannot extract page {n} from end", file=sys.stderr)
            sys.exit(1)

        # n=1 means last page (index -1), n=2 means second-to-last (index -2), etc.
        target_idx = len(images) - n
        target_image = images[target_idx]

        ext = Path(target_image).suffix.lower()
        output_name = f"{cbz_path.stem}_page{len(images) - n + 1}{ext}"
        output_path = cbz_path.parent / output_name

        data = cbz.read(target_image)
        output_path.write_bytes(data)
        print(f"Extracted: {output_path}")


def is_two_page_spread(img: Image.Image) -> bool:
    """Check if image is a two-page spread (width > height)."""
    return img.width > img.height


def split_spread(img: Image.Image, ltr: bool) -> tuple[Image.Image, Image.Image]:
    """Split a two-page spread into two images.

    For RTL (default): returns (right_half, left_half) - right page comes first
    For LTR: returns (left_half, right_half) - left page comes first
    """
    mid = img.width // 2
    left_half = img.crop((0, 0, mid, img.height))
    right_half = img.crop((mid, 0, img.width, img.height))

    if ltr:
        return left_half, right_half
    else:
        return right_half, left_half


def image_to_bytes(img: Image.Image, fmt: str) -> bytes:
    """Convert PIL Image to bytes."""
    buf = io.BytesIO()
    # Handle format mapping
    save_fmt = fmt.upper()
    if save_fmt == "JPG":
        save_fmt = "JPEG"
    img.save(buf, format=save_fmt)
    return buf.getvalue()


def format_cbz(cbz_path: Path, ltr: bool = False) -> None:
    """Format CBZ: split two-page spreads into individual pages."""
    if not cbz_path.exists():
        print(f"Error: File not found: {cbz_path}", file=sys.stderr)
        sys.exit(1)

    temp_fd, temp_path = tempfile.mkstemp(suffix=".cbz", dir=cbz_path.parent)
    try:
        with zipfile.ZipFile(cbz_path, "r") as cbz_in:
            images = get_image_files(cbz_in)
            if not images:
                print("No images found in CBZ.", file=sys.stderr)
                sys.exit(1)

            print(f"Processing {len(images)} images...")
            spreads_split = 0
            output_images: list[tuple[str, bytes]] = []

            for img_path in images:
                data = cbz_in.read(img_path)
                ext = Path(img_path).suffix.lower().lstrip(".")

                try:
                    img = Image.open(io.BytesIO(data))

                    if is_two_page_spread(img):
                        # Split the spread
                        first_page, second_page = split_spread(img, ltr)
                        output_images.append((f"split.{ext}", image_to_bytes(first_page, ext)))
                        output_images.append((f"split.{ext}", image_to_bytes(second_page, ext)))
                        spreads_split += 1
                    else:
                        # Keep single page as-is
                        output_images.append((img_path, data))
                except Exception as e:
                    print(f"Warning: Could not process {img_path}: {e}", file=sys.stderr)
                    output_images.append((img_path, data))

            # Write output CBZ with renumbered images
            with zipfile.ZipFile(temp_path, "w", zipfile.ZIP_DEFLATED) as cbz_out:
                for idx, (original_path, img_data) in enumerate(output_images, 1):
                    ext = Path(original_path).suffix.lower()
                    new_name = f"{idx:03d}{ext}"
                    cbz_out.writestr(new_name, img_data)

        Path(temp_path).replace(cbz_path)
        direction = "LTR" if ltr else "RTL"
        print(f"Formatted ({direction}): {cbz_path}")
        print(f"  Split {spreads_split} spreads, {len(output_images)} total pages")
    finally:
        try:
            os.close(temp_fd)
        except OSError:
            pass
        try:
            Path(temp_path).unlink(missing_ok=True)
        except OSError:
            pass


def add_page_after_cover(cbz_path: Path) -> None:
    """Add a blank page after the cover, matching the cover's dimensions."""
    if not cbz_path.exists():
        print(f"Error: File not found: {cbz_path}", file=sys.stderr)
        sys.exit(1)

    temp_fd, temp_path = tempfile.mkstemp(suffix=".cbz", dir=cbz_path.parent)
    try:
        with zipfile.ZipFile(cbz_path, "r") as cbz_in:
            images = get_image_files(cbz_in)
            if not images:
                print("No images found in CBZ.", file=sys.stderr)
                sys.exit(1)

            # Read cover image to get dimensions
            cover_path = images[0]
            cover_data = cbz_in.read(cover_path)
            cover_img = Image.open(io.BytesIO(cover_data))
            cover_ext = Path(cover_path).suffix.lower().lstrip(".")

            # Create blank page same size as cover (white)
            blank_page = Image.new("RGB", (cover_img.width, cover_img.height), (255, 255, 255))
            blank_data = image_to_bytes(blank_page, cover_ext)

            # Write output CBZ: cover, blank page, then rest
            with zipfile.ZipFile(temp_path, "w", zipfile.ZIP_DEFLATED) as cbz_out:
                # Page 1: cover
                ext = Path(cover_path).suffix.lower()
                cbz_out.writestr(f"001{ext}", cover_data)

                # Page 2: blank page
                cbz_out.writestr(f"002{ext}", blank_data)

                # Pages 3+: remaining images
                for idx, img_path in enumerate(images[1:], 3):
                    data = cbz_in.read(img_path)
                    img_ext = Path(img_path).suffix.lower()
                    cbz_out.writestr(f"{idx:03d}{img_ext}", data)

        Path(temp_path).replace(cbz_path)
        print(f"Added blank page after cover: {cbz_path}")
        print(f"  Cover size: {cover_img.width}x{cover_img.height}, now {len(images) + 1} pages")
    finally:
        try:
            os.close(temp_fd)
        except OSError:
            pass
        try:
            Path(temp_path).unlink(missing_ok=True)
        except OSError:
            pass


def convert_to_webp(cbz_path: Path, lossy: bool = False, quality: int = 90) -> None:
    """Convert all images in CBZ to WebP format."""
    if not cbz_path.exists():
        print(f"Error: File not found: {cbz_path}", file=sys.stderr)
        sys.exit(1)

    temp_fd, temp_path = tempfile.mkstemp(suffix=".cbz", dir=cbz_path.parent)
    try:
        with zipfile.ZipFile(cbz_path, "r") as cbz_in:
            images = get_image_files(cbz_in)
            if not images:
                print("No images found in CBZ.", file=sys.stderr)
                sys.exit(1)

            # Check if already all WebP
            non_webp = [img for img in images if not img.lower().endswith(".webp")]
            if not non_webp:
                print(f"All images already WebP: {cbz_path}")
                return

            mode = f"lossy (quality={quality})" if lossy else "lossless"
            total = len(images)
            print(f"Converting {total} images to WebP ({mode})...")

            original_size = 0
            new_size = 0

            with zipfile.ZipFile(temp_path, "w", zipfile.ZIP_STORED) as cbz_out:
                for idx, img_path in enumerate(images, 1):
                    print(f"\r  Processing {idx}/{total}...", end="", flush=True)
                    data = cbz_in.read(img_path)
                    original_size += len(data)

                    # If already WebP, keep as-is
                    if img_path.lower().endswith(".webp"):
                        new_name = f"{idx:03d}.webp"
                        cbz_out.writestr(new_name, data)
                        new_size += len(data)
                        continue

                    try:
                        img = Image.open(io.BytesIO(data))

                        # Convert to RGB if necessary (WebP doesn't support all modes)
                        if img.mode in ("RGBA", "LA", "PA"):
                            # Keep alpha for formats that have it
                            pass
                        elif img.mode != "RGB":
                            img = img.convert("RGB")

                        buf = io.BytesIO()
                        if lossy:
                            img.save(buf, format="WEBP", quality=quality)
                        else:
                            img.save(buf, format="WEBP", lossless=True)

                        webp_data = buf.getvalue()
                        new_name = f"{idx:03d}.webp"
                        cbz_out.writestr(new_name, webp_data)
                        new_size += len(webp_data)

                    except Exception as e:
                        print(f"\nWarning: Could not convert {img_path}: {e}", file=sys.stderr)
                        # Keep original
                        ext = Path(img_path).suffix.lower()
                        new_name = f"{idx:03d}{ext}"
                        cbz_out.writestr(new_name, data)
                        new_size += len(data)

            print()  # Clear progress line
        Path(temp_path).replace(cbz_path)
        reduction = (1 - new_size / original_size) * 100 if original_size > 0 else 0
        print(f"Converted to WebP: {cbz_path}")
        print(f"  {original_size // 1024:,} KB -> {new_size // 1024:,} KB ({reduction:.1f}% reduction)")
    finally:
        try:
            os.close(temp_fd)
        except OSError:
            pass
        try:
            Path(temp_path).unlink(missing_ok=True)
        except OSError:
            pass


def main():
    parser = argparse.ArgumentParser(
        description="CBZ utilities: convert, rename, extract, split, add page, webp"
    )

    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument("-c", "--convert", action="store_true",
                       help="Convert EPUB/PDF to CBZ (keeps original format unless --webp)")
    group.add_argument("-r", "--rename", action="store_true",
                       help="Rename images to 001, 002, ...")
    group.add_argument("-e", "--extract", type=int, metavar="N",
                       help="Extract Nth page from end (1=last)")
    group.add_argument("-s", "--split", action="store_true",
                       help="Split two-page spreads")
    group.add_argument("-a", "--add-page", action="store_true",
                       help="Add blank page after cover")
    group.add_argument("-w", "--webp", action="store_true",
                       help="Convert images to WebP")

    parser.add_argument("files", nargs="*",
                        help="Input files (default: all .epub or .cbz in current dir)")

    parser.add_argument("--ltr", action="store_true",
                        help="Left-to-right reading order (default is RTL)")
    parser.add_argument("-q", "--quality", type=int, default=85, metavar="Q",
                        help="WebP quality 1-100 (default: 85)")
    parser.add_argument("--lossless", action="store_true",
                        help="Use lossless WebP (default is lossy)")

    args = parser.parse_args()

    def get_default_files(pattern: str) -> list[Path]:
        """Get all files matching pattern in current directory, sorted."""
        files = sorted(Path(".").glob(pattern))
        if not files:
            print(f"No {pattern} files found in current directory.", file=sys.stderr)
            sys.exit(1)
        return files

    def get_input_files(pattern: str) -> list[Path]:
        """Get input files from args or default to pattern in current dir."""
        if args.files:
            return [Path(f) for f in args.files]
        return get_default_files(pattern)

    if args.convert:
        if args.files:
            files = [Path(f) for f in args.files]
        else:
            # Find both EPUB and PDF files
            epubs = sorted(Path(".").glob("*.epub"))
            pdfs = sorted(Path(".").glob("*.pdf"))
            files = epubs + pdfs
            if not files:
                print("No .epub or .pdf files found in current directory.", file=sys.stderr)
                sys.exit(1)
        for f in files:
            if len(files) > 1:
                print(f"\n=== {f} ===")
            ext = f.suffix.lower()
            if ext == ".pdf":
                convert_pdf_to_cbz(f, use_webp=args.webp, quality=args.quality)
            elif ext == ".epub":
                convert_epub_to_cbz(f, use_webp=args.webp, quality=args.quality)
            else:
                print(f"Error: Unsupported format {ext}, use .epub or .pdf", file=sys.stderr)
                sys.exit(1)
    elif args.rename:
        files = get_input_files("*.cbz")
        for f in files:
            if len(files) > 1:
                print(f"\n=== {f} ===")
            rename_images_in_cbz(f)
    elif args.extract:
        files = get_input_files("*.cbz")
        for f in files:
            if len(files) > 1:
                print(f"\n=== {f} ===")
            extract_page_from_end(f, args.extract)
    elif args.split:
        files = get_input_files("*.cbz")
        for f in files:
            if len(files) > 1:
                print(f"\n=== {f} ===")
            format_cbz(f, ltr=args.ltr)
    elif args.add_page:
        files = get_input_files("*.cbz")
        for f in files:
            if len(files) > 1:
                print(f"\n=== {f} ===")
            add_page_after_cover(f)
    elif args.webp:
        files = get_input_files("*.cbz")
        for f in files:
            if len(files) > 1:
                print(f"\n=== {f} ===")
            convert_to_webp(f, lossy=not args.lossless, quality=args.quality)


if __name__ == "__main__":
    main()